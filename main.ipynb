{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDataset columns:\\n\\n'Property Name' - name of the hotel, not used\\n'Review Rating' - integer rating from 1 to 5, this is the 'y' part of our model\\n'Review Title' - not used \\n'Review Text' - this is the 'x' part of our model\\n'Location Of The Reviewer' - not used\\n'Date Of Review' - not used\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_csv('london_hotel_reviews.csv', encoding = 'latin-1')\n",
    "\n",
    "# set some display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\"\"\"\n",
    "Dataset columns:\n",
    "\n",
    "'Property Name' - name of the hotel, not used\n",
    "'Review Rating' - integer rating from 1 to 5, this is the 'y' part of our model\n",
    "'Review Title' - not used \n",
    "'Review Text' - this is the 'x' part of our model\n",
    "'Location Of The Reviewer' - not used\n",
    "'Date Of Review' - not used\n",
    "\"\"\"\n",
    "\n",
    "#print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def process_dataset(data):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with 3 columns: Review Rating, Review Text, and Processed Text\n",
    "    \n",
    "    Processed text is a list of words ready for feature extraction\n",
    "    \"\"\"\n",
    "\n",
    "    data['temp'] = data['Review Text'].map(utils.in_english)\n",
    "    data = data[data['temp'] == True]\n",
    "    data = data.drop(columns = ['temp', 'Property Name', 'Review Title', 'Location Of The Reviewer', 'Date Of Review'])\n",
    "    \n",
    "    data['Processed Text'] = data['Review Text'].map(utils.clean_text)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_matrix_data(data):\n",
    "    \"\"\"\n",
    "    Returns a (n, m) matrix and an array of length n\n",
    "    Bag of 1-grams model\n",
    "\n",
    "    This function does the actual feature extraction\n",
    "    \"\"\"\n",
    "\n",
    "    vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "    X = vectorizer.fit_transform(data['Processed Text']).toarray()\n",
    "    y = data['Review Rating'].to_numpy()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def get_matrix_data2(data):\n",
    "    \"\"\"\n",
    "    Same as previous but applies tf-idf over the bag of 1-grams\n",
    "    \"\"\"\n",
    "\n",
    "    vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "    X = vectorizer.fit_transform(data['Processed Text']).toarray()\n",
    "    X = TfidfTransformer().fit_transform(X).toarray()\n",
    "    y = data['Review Rating'].to_numpy()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def logistic_classifier(X_train, y_train, _C = 1.0):\n",
    "    return LogisticRegression(C=_C).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = process_dataset(input_data)\n",
    "processed_data_bin = processed_data.copy()\n",
    "processed_data_bin['Review Rating'] = processed_data_bin['Review Rating'].map(lambda x : 1 if x > 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data.to_csv(r'processed_data_export.csv')\n",
    "# processed_data_bin.to_csv(r'processed_data_bin_export.csv')\n",
    "\n",
    "#processed_data = pd.read_csv('processed_data_export.csv', encoding='latin-1')\n",
    "#processed_data_bin = pd.read_csv('processed_data_bin_export.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xoxo/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#X, y = get_matrix_data(processed_data)\n",
    "#X_train, y_train, X_test, y_test = utils.split_matrix_data(X, y, 0.9)\n",
    "\n",
    "X_bin, y_bin = get_matrix_data2(processed_data_bin)\n",
    "X_bin_train, y_bin_train, X_bin_test, y_bin_test = utils.split_matrix_data(X_bin, y_bin, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xoxo/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7493495229835212"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression = LogisticRegression(C=1.6,max_iter=150).fit(X_train, y_train)\n",
    "\n",
    "regression.score(X_test, y_test)\n",
    "\n",
    "# 5 classes accuracy (rating is from 1 to 5):\n",
    "# bag of words: ~74%\n",
    "# tf-idf: ~75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47528187337380745"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(force_alpha=True)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "nb.score(X_test, y_test)\n",
    "\n",
    "# 5 classes accuracy (rating is from 1 to 5):\n",
    "# bag of words: ~72.5%\n",
    "# tf-idf: ~69%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9336513443191674"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(force_alpha=True).fit(X_bin_train, y_bin_train)\n",
    "nb.score(X_bin_test, y_bin_test)\n",
    "\n",
    "# 2 classes accuracy (positive or negative):\n",
    "# bag of words: ~93%\n",
    "# tf-idf: ~89%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a31d4a897fa320092646c82eed56feb6bea21b6f17b9706ff3bf201fa23bd5ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
